from typing import Sequence, Annotated
from langchain_core.messages import BaseMessage
from langgraph.graph import StateGraph
from datetime import datetime
from typing import Annotated,Sequence, TypedDict
import operator
from langgraph.graph import StateGraph
from langchain_core.messages import BaseMessage, BaseMessage
from langgraph.prebuilt import ToolNode, tools_condition
from langgraph.checkpoint.memory import MemorySaver
from pydantic import BaseModel, Field
from typing import List, Optional, Sequence, Annotated
from typing_extensions import TypedDict
from aimode.core.tools import sql_query_generator, execute_sql_query, generate_testplan
from aimode.core.prompts import AGENT_PROMPT, SUGGESTION_LLM_PROMPT
from aimode.core.llms import llm


class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], operator.add]


class GetSuggestions(BaseModel):
    """To get suggestions in structured format"""

    base_content: str = Field(..., description="Raw base content generated by LLM")
    suggestions: Optional[List[str]] = Field(
        None, description="List of suggested options"
    )


tools = [sql_query_generator, execute_sql_query, generate_testplan]
llm_with_tools = AGENT_PROMPT | llm.bind_tools(tools)


def chatbot(state: AgentState):
    messages = state['messages']
    response = llm_with_tools.invoke({"messages": messages})


    if hasattr(response, 'content'):
        content_to_structure = response.content
    else:
        content_to_structure = str(response)

    chain = SUGGESTION_LLM_PROMPT | llm.with_structured_output(
        GetSuggestions, 
        method="function_calling"
    )
    
    structured = chain.invoke({"content": content_to_structure})

    if hasattr(response, 'additional_kwargs'):
        response.additional_kwargs["structured"] = structured.dict()
    else:
        response.structured = structured.dict()

    return {'messages': [response]}

workflow = StateGraph(AgentState)
workflow.add_node("chatbot",chatbot)
workflow.add_node("tools",ToolNode(tools))
workflow.add_conditional_edges(
    "chatbot",
    tools_condition,
)
workflow.add_edge("tools", "chatbot")
workflow.set_entry_point("chatbot")

memory = MemorySaver()
graph = workflow.compile()
graph = workflow.compile(checkpointer=memory)







if __name__== "__main__":
    from langchain_core.messages import HumanMessage
    messages = graph.invoke({"messages": [HumanMessage(content="Hii, Generate testplan  for module Player and Launcher with 5 outputs.")]})
    ai_message = messages["messages"][-1]
    print('AIMSG: ', ai_message.content)
    print('AIMSG_additional_kwargs: ', ai_message.additional_kwargs.get('structured', {}))